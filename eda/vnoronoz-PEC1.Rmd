---
title: 'Minería de datos: PEC1'
author: "Autor: **VANESA NAVARRO ORONOZ**"
date: "Octubre 2020"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

******
# Introducción
******
## Presentación
Esta prueba de evaluación continuada cubre el módulo 1,2 y 8 del programa de la asignatura.  

## Competencias
Las competencias que se trabajan en esta prueba son:

* Uso y aplicación de las TIC en el ámbito académico y profesional
* Capacidad para innovar y generar nuevas ideas.
* Capacidad para evaluar soluciones tecnológicas y elaborar propuestas de proyectos teniendo en cuenta los recursos, las alternativas disponibles y las condiciones de mercado.
* Conocer las tecnologías de comunicaciones actuales y emergentes, así como saberlas aplicar convenientemente para diseñar y desarrollar soluciones basadas en sistemas y tecnologías de la información.
* Aplicación de las técnicas específicas de ingeniería del software en las diferentes etapas del ciclo de vida de un proyecto.
* Capacidad para aplicar las técnicas específicas de tratamiento, almacenamiento y administración de datos.
* Capacidad para proponer y evaluar diferentes alternativas tecnológicas para resolver un problema concreto.
* Capacidad de utilizar un lenguaje de programación.  
* Capacidad para desarrollar en una herramienta IDE.  
* Capacidad de plantear un proyecto de minería de datos.  

## Objetivos
* Asimilar correctamente el módulo 1 y 2.
*	Qué es y qué no es MD.
*	Ciclo de vida de los proyectos de MD.
*	Diferentes tipologías de MD.
* Conocer las técnicas propias de una fase de preparación de datos y objetivos a alcanzar.  

## Descripción de la PEC a realizar
La prueba está estructurada en 1 ejercicio teórico/práctico y 1 ejercicio práctico que pide que se desarrolle la fase de preparación en un juego de datos.  
Deben responderse todos los ejercicios para poder superar la PEC.  

## Recursos
Para realizar esta práctica recomendamos la lectura de los siguientes documentos:  

* Módulo 1, 2 y 8 del material didáctico.  
* RStudio Cheat Sheet: Disponible en el aula Laboratorio de Minería de datos.  
* R Base Cheat Sheet: Disponible en el aula Laboratorio de Minería de datos.  

## Criterios de evaluación
**Ejercicios teóricos**  
Todos los ejercicios deben ser presentados de forma razonada y clara, especificando todos y cada uno de los pasos que se hayan llevado a cabo para su resolución. No se aceptará ninguna respuesta que no esté claramente justificada.  

**Ejercicios prácticos**  
Para todas las PEC es necesario documentar en cada apartado del ejercicio práctico qué se ha hecho y cómo se ha hecho.  

## Formato y fecha de entrega
El formato de entrega es: usernameestudiant-PECn.html y rmd  
Fecha de Entrega: 28/10/2020  
Se debe entregar la PEC en el buzón de entregas del aula  


## Nota: Propiedad intelectual 

> A menudo es inevitable, al producir una obra multimedia, hacer uso de recursos creados por terceras personas. Es por lo tanto comprensible hacerlo en el marco de una práctica de los estudios de Informática, Multimedia y Telecomunicación de la UOC, siempre y cuando esto se documente claramente y no suponga plagio en la práctica. 

> Por lo tanto, al presentar una práctica que haga uso de recursos ajenos, se debe presentar junto con ella un documento en qué se detallen todos ellos, especificando el nombre de cada recurso, su autor, el lugar dónde se obtuvo y su estatus legal: si la obra está protegida por el copyright o se acoge a alguna otra licencia de uso (Creative Commons, licencia GNU, GPL ...). 
El estudiante deberá asegurarse de que la licencia  no impide específicamente su uso en el marco de la práctica. En caso de no encontrar la información correspondiente tendrá que asumir que la obra está protegida por copyright. 

> Deberéis, además, adjuntar los ficheros originales cuando las obras utilizadas sean digitales, y su código fuente si corresponde.  

******
# Enunciado  
******
Como ejemplo, trabajaremos con el conjunto de datos "Titanic" que recoge datos sobre el famoso crucero y sobre el que es fácil realizar tareas de clasificación predictiva sobre la variable "Survived".   

De momento dejaremos para las siguientes prácticas el estudio de algoritmos predictivos y nos centraremos por ahora en el estudio de las variables de una muestra de datos, es decir, haremos un trabajo descriptivo del mismo. 

Las actividades que llevaremos a cabo en esta práctica suelen enmarcarse en las fases iniciales de un proyecto de minería de datos y consisten en la selección de características o variables y la preparación del los  datos para posteriormente ser consumido por un algoritmo.

Las técnicas que trabajaremos son las siguientes:  

1. Normalización  
2. Discretización  
3. Gestión de valores nulos  
4. Estudio de correlaciones  
5. Reducción de la dimensionalidad
6. Análisis visual del conjunto de datos  

******
# Ejemplo de estudio visual con el juego de datos Titanic
******

## Procesos de limpieza del conjunto de datos

Primer contacto con el conjunto de datos, visualizamos su estructura.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)

# Cargamos el fichero de datos
totalData <- read.csv('titanic.csv',stringsAsFactors = FALSE)
filas=dim(totalData)[1]

# Verificamos la estructura del conjunto de datos
str(totalData)
```
Descripción de las variables contenidas en el fichero:

name
    a string with the name of the passenger.
    
gender
    a factor with levels male and female.
    
age
    a numeric value with the persons age on the day of the sinking. The age of babies (under 12 months) is given as a fraction of one year (1/month).
    
class
    a factor specifying the class for passengers or the type of service aboard for crew members.
    
embarked
    a factor with the persons place of of embarkment.
    
country
    a factor with the persons home country.
    
ticketno
    a numeric value specifying the persons ticket number (NA for crew members).
    
fare
    a numeric value with the ticket price (NA for crew members, musicians and employees of the shipyard company).
    
sibsp
    an ordered factor specifying the number if siblings/spouses aboard; adopted from Vanderbild data set.
    
parch
    an ordered factor specifying the number of parents/children aboard; adopted from Vanderbild data set.
    
survived
    a factor with two levels (no and yes) specifying whether the person has survived the sinking.
    

Mostramos estadísticas bàsicas y después trabajamos los atributos con valores vacíos.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Estadísticas básicas
summary(totalData)

# Estadísticas de valores vacíos
colSums(is.na(totalData))
colSums(totalData=="")

# Tomamos valor "Desconocido" para los valores vacíos de la variable "country"
totalData$Embarked[totalData$country==""]="Desconocido"

# Tomamos la media para valores vacíos de la variable "Age"
totalData$Age[is.na(totalData$age)] <- mean(totalData$age,na.rm=T)
```

Discretizamos cuando tiene sentido y en función de las capacidades de cada variable.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Añadimos una variable nueva a los datos. Este valor es la edad discretizada con un método simple de intervalos de igual amplitud.
# Vemos cómo se distribuyen los valore
summary(totalData[,"age"])
# Discretizamos
totalData["segmento_edad"] <- cut(totalData$age, breaks = c(0,10,20,30,40,50,60,70,100), labels = c("0-9", "10-19", "20-29", "30-39","40-49","50-59","60-69","70-79"))
# Observamos los datos discretizados.
head(totalData)
# Vemos como se agrupan los datos.
plot(totalData$segmento_edad)
```


## Procesos de análisis del conjunto de datos

Nos proponemos analizar las relaciones entre las diferentes variables del conjunto de datos para ver si se relacionan y como.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Visualizamos la relación entre las variables "sex" y "survival":
ggplot(data=totalData[1:filas,],aes(x=gender,fill=survived))+geom_bar()

# Otro punto de vista. Survival como función de Embarked:
ggplot(data = totalData[1:filas,],aes(x=embarked,fill=survived))+geom_bar(position="fill")+ylab("Frecuencia")

```

En la primera gráfica podemos observar fácilmente la cantidad de mujeres que viajaban respecto hombres y observar los que no sobrevivieron. Numéricamente el número de hombres y mujeres supervivientes es similar.

En la segunda gráfica de forma porcentual observamos los puertos de embarque y los porcentajes de supervivencia en función del puerto. Se podría trabajar el puerto C (Cherburgo) para ver de explicar la diferencia en los datos. Quizás porcentualmente embarcaron más mujeres o niños... O gente de primera clase?

Obtenemos ahora una matriz de porcentajes de frecuencia.
Vemos, por ejemplo que la probabilidad de sobrevivir si se embarcó en "C" es de un 56.45%

```{r echo=TRUE, message=FALSE, warning=FALSE}
t<-table(totalData[1:filas,]$embarked,totalData[1:filas,]$survived)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
t
```

Veamos ahora como en un mismo gráfico de frecuencias podemos trabajar con 3 variables: Embarked, Survived y Pclass.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Ahora, podemos dividir el gráfico de Embarked por Pclass:
ggplot(data = totalData[1:filas,],aes(x=embarked,fill=survived))+geom_bar(position="fill")+facet_wrap(~class)
```

Aquí ya podemos extraer mucha información. Como propuesta de mejora se podría hacer un gráfico similar trabajando solo la clase. Habría que unificar toda la tripulación a una única categoría.

Comparemos ahora dos gráficos de frecuencias: Survived-SibSp y Survived-Parch

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survivial como función de SibSp y Parch
ggplot(data = totalData[1:filas,],aes(x=sibsp,fill=survived))+geom_bar()
ggplot(data = totalData[1:filas,],aes(x=parch,fill=survived))+geom_bar()
# Vemos como las forma de estos dos gráficos es similar. Este hecho nos puede indicar presencia de correlaciones altas.
```

Veamos un ejemplo de construcción de una variable nueva: Tamaño de familia

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Construimos un atributo nuevo: family size.
totalData$FamilySize <- totalData$sibsp + totalData$parch +1;
totalData1<-totalData[1:filas,]
ggplot(data = totalData1[!is.na(totalData[1:filas,]$FamilySize),],aes(x=FamilySize,fill=survived))+geom_histogram(binwidth =1,position="fill")+ylab("Frecuencia")

  
```

Veamos ahora dos gráficos que nos compara los atributos Age y Survived.  
Observamos como el parámetro position="fill" nos da la proporción acumulada de un atributo dentro de otro

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survival como función de age:
ggplot(data = totalData1[!(is.na(totalData[1:filas,]$age)),],aes(x=age,fill=survived))+geom_histogram(binwidth =3)
ggplot(data = totalData1[!is.na(totalData[1:filas,]$age),],aes(x=age,fill=survived))+geom_histogram(binwidth = 3,position="fill")+ylab("Frecuencia")
```



******
# Ejercicios
******

## Ejercicio 1: 

Estudia los tres casos siguientes y contesta, de forma razonada la pregunta que se realiza:

* Disponemos de un conjunto de variables referentes a vehículos, tales como la marca, modelo, año de matriculación, etc. También se dispone del precio al que se vendieron. Al poner a la venta a un nuevo vehículo, se dispone de las variables que lo describen, pero se desconoce el precio. ¿Qué tipo de algoritmo se debería aplicar para predecir de forma automática el precio?

* En un almacén de naranjas se tiene una máquina, que de forma automática obtiene un conjunto de variables de cada naranja, como su tamaño, acidez, grado maduración, etc. Si se desea estudiar las naranjas por tipos, según las variables obtenidas, ¿qué tipo de algoritmo es el más adecuado?

* Un servicio de música por internet dispone de los historiales de audición de sus clientes: Qué canciones y qué grupos eligen los clientes a lo largo del tiempo de sus escuchas. La empresa desea crear un sistema  que proponga la siguiente canción y grupo en función de la canción que se ha escuchado antes. ¿Qué tipo de algoritmo es el más adecuado?

### Respuesta 1:
* Para el primer caso, estaríamos hablando de una tarea de **clasificación**. La tarea de clasificación consiste en asignar instancias de un dominio dado, descritas por un conjunto de atributos discretos o de valor continuo, a un conjunto de clases, que pueden ser consideradas valores de un atributo discreto seleccionado, generalmente denominado clase. Es necesario disponer de un subconjunto de datos correctamente etiquetado, y que se usará para la construcción del modelo (en este caso sería losprecios de los coches que ya han sido vendidos).Un problema de clasificación puede aceptar técnicas de análisis discriminante, de árboles de decisión, de redes neuronales, máquinas de soporte vectorial o de k-NN.

* En el segundo caso, lo que se pretende **encontrar similitudes y agrupar objetos parecidos**, osea agrupar naranjas que tengan características similares. Los modelos típicos para alcanzar estos objetivos son los **modelos de agregación (clustering)**. La tarea de agrupamiento consiste en dividir un conjunto de instancias de un dominio dado, descrito por un número de atributos discretos o de valor continuo, en un conjunto de grupos (clústeres) basándose en la similitud entre las instancias, y crear un modelo que puede asignar nuevas instancias a uno de estos grupos o clústeres. Un problema de segmentación puede aceptar técnicas de clustering, de redes neuronales o simplemente técnicas de visualización.

* Por último, para el caso del servicio de música, se necesitaría realizar un **análisis de dependencias, descripción y predicción**. Se trata de obtener conocimiento que nos permita predecir aquello que nos interese. Presenta muchas similitudes con la clasificación. Un problema de predicción y análisis de dependencias puede afrontarse con técnicas como reglas de asociación, redes bayesianas, análisis de regresión, análisis de correlaciones y árboles de decisión.


## Ejercicio 2:  
A partir del conjunto de datos disponible en el siguiente enlace http://archive.ics.uci.edu/ml/datasets/Adult , realiza un estudio tomando como propuesta inicial al que se ha realizado con el conjunto de datos "Titanic". Amplia la propuesta generando nuevos indicadores o solucionando otros problemas expuestos en el módulo 2. Explica el proceso que has seguido, qué conocimiento obtienes de los datos, qué objetivo te has fijado y detalla los pasos, técnicas usadas y los problemas resueltos.

Nota: Si lo deseas puedes utilizar otro conjunto de datos propio o de algún repositorio open data siempre que sea similar en diversidad de tipos de variables al propuesto. 

### Respuesta 2:

**Origen y obtención de los datos**

Como se puede ver al inspeccionar el juego de datos, y también se ha explicado en el Foro; para el dataset Adult existen dos archivos de datos: adult.data y adult.test. Para la PEC se deben en tener en cuenta los dos. Por lo tanto, leemos ambos archivos directamente del [repositorio de Machine Learning de la UCI](https://archive.ics.uci.edu/ml/datasets/adult):

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)
library(scales)
# Cargamos los dos archivos del juego de datos
# Primero el archivo adult.data 
# Indicamos que el archivo no tiene cabecera, que las cadenas se lean como factores, que las celdas que no tienen valor estan con el caracter " ?" y que corte el espacio en blanco que hay delante de cada dato
adult_data <- read.csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', stringsAsFactors = TRUE, header = FALSE, na.strings = '?', strip.white = TRUE)

colnames(adult_data) <- c('age', 'workclass', 'fnlwgt', 'education', 
                     'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income')

# Segundo el archivo adult.test y nombres de sus atributos
# Indicamos que salte la primera fila, que las cadenas se lean como factores, que las celdas que no tienen valor estan con el caracter "?" y que corte el espacio en blanco que hay delante de cada dato
adult_test <- read.csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test',  stringsAsFactors = TRUE, header = FALSE, skip = 1, na.strings = '?', strip.white = TRUE)

colnames(adult_test) <- c('age', 'workclass', 'fnlwgt', 'education', 
                     'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income')
```

Para trabajar conjuntamente con todos los registros, es necesario unir los dos archivos. Como ya hemos comprobado que ambos tienen las mismas columnas, podemos unirlos con la función `rbind`.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Unión de adult.data y adult.test
datos_adult <- rbind(adult_data, adult_test)
```

El número de **resgistros** en el archivo es:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Usamos dim que nos devuelve las filas y columnas del objeto
dim(datos_adult)[1]
```

El número de **variables** en el archivo es:

```{r echo=TRUE, message=FALSE, warning=FALSE}
dim(datos_adult)[2]
```
A continuación revisamos la estructura del archivo con la funcion `str()` que muestra de forma compacta la estructura interna de un objeto.

```{r echo=TRUE, message=FALSE, warning=FALSE}
str(datos_adult)
```
Echamos un vistazo general a las variables, sus tipos y valores. La función `summary` nos permite hacer una descriptiva rápida de las variables de tipo numérico. En concreto, nos muestra la mediana, la desviación estándard, el mínimo, el máximo y los cuartiles de las variables.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estadísticas básicas
summary(datos_adult)
```
Echamos un vistazo a las primeras y últimas filas del archivo:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cabecera
head(datos_adult)
```
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cola
tail(datos_adult)
```

Resumimos en una tabla las variables encontradas, su tipo y descripción:

VARIABLE      | TIPO     | VALORES            | DESCRIPCIÓN
-----------   | -------- | ----------------   | ------------------
age           | integer  |Min: 17 Max: 90     |Edad de la persona
workclass     | factor|Federal-gov, Local-gov, Never-worked, Private, Self-emp-inc, Self-emp-not-inc, State-gov, Without-pay|Situación laboral
fnlwgt        | integer  |Min: 12285 Max: 1490400|Peso final de la población que representa (la cantidad de personas que cree el censo que la entrada representa)
education     | factor|10th, 11th, 12th, 1st-4th, 5th-6th, 7th-8th, 9th, Assoc-acdm, Assoc-voc, Bachelors, Doctorate, HS-grad, Masters, Preschool, Prof-school, Some-college|Nivel de educación máximo logrado
education_num | integer  |Min: 1 Max: 16      |Nivel de educación máximo logrado (numérico)
marital_status| factor|Divorced, Married-AF-spouse, Married-civ-spouse, Married-spouse-absent, Never-married, Separated, Widowed             |Estado civil de la persona
occupation    | factor|Adm-clerical, Armed-Forces, Craft-repair, Exec-managerial, Farming-fishing, Handlers-cleaners, Machine-op-inspct, Other-service, Priv-house-serv, Prof-specialty, Protective-serv, Sales, Tech-support, Transport-moving                |Ocupación de la persona
relationship  | factor|Husband, Not-in-family, Other-relative, Own-child, Unmarried, Wife|Tipo de relación (representa lo que este individuo es en relación con los demás)
race          | factor|Amer-Indian-Eskimo, Asian-Pac-Islander, Black, Other, White|Raza de la persona
sex           | factor|Female, Male        |Sexo biológico de la persona
capital_gain  | integer  |Min: 0 Max: 99999   |Ganancias
capital_loss  | integer  |Min: 0 Max: 4356    |Pérdidas
hours_per_week| integer  |Min: 1 Max: 99      |Horas trabajadas por semana
native_country| factor|Cambodia, Canada, China, Columbia, Cuba, Dominican-Republic, Ecuador, El-Salvador, England, France, Germany, Greece, Guatemala, Haiti, Holand-Netherlands, Honduras, Hong, Hungary, India, Iran, Ireland, Italy, Jamaica, Japan, Laos, Mexico, Nicaragua, Outlying-US(Guam-USVI-etc), Peru, Philippines, Poland, Portugal, Puerto-Rico, Scotland, South, Taiwan, Thailand, Trinadad&Tobago, United-States, Vietnam, Yugoslavia                                    |País de origen
income        | factor|<=50K, >50K         |Nivel de ingresos (si una persona gana o no más de $50,000 al año)

**Preparación y limpieza de los datos**

Para la **gestión de valores nulos** primeramente sacamos el total de filas con valores NA en la tabla:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estadísticas de valores vacíos
colSums(is.na(datos_adult))
```
Al leer la tabla le indicamos que los valores "?" los catalogara como sin datos NA. Ahora vemos que en la columna workclass hay 2799 registros sin datos, en occupation 2809 y en native_country 857. Para este caso de estudio y como no se especifica nada en el enunciado, elegimos **eliminar esos registros** de la tabla ya que suponen un pequeño porcentaje del total.

```{r echo=TRUE, message=FALSE, warning=FALSE}
datos_adult <- na.omit(datos_adult)
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
dim(datos_adult)
```
Vamos a **reducir la dimensionalidad** del conjunto de datos eliminando algunos de sus atributos, ya porque sean redundantes o bien porque carecen de valor para nuestro análisis. En este caso, eliminaremos el atributo `education_num` porque nos vamos a quedar con la misma información pero en el campo `education`. También eliminamos los campos `fnlwgt` y `relationship` porque no lo utilizaremos en este análisis.

```{r echo=TRUE, message=FALSE, warning=FALSE}
datos_adult <- datos_adult[,-c(3,5,8)]
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
dim(datos_adult)
```
En el caso de los campos `capital_gain` y `capital_loss` vamos a crear un nuevo atributo que se denimine `capital` y sea la diferencia de las ganacias y las pérdidas. De esta forma nos quedaremos solo con ese campo y borraremos los originales.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Creamos el campo capital
datos_adult <- mutate(datos_adult,capital = capital_gain - capital_loss)
# Borramos capital_gain y capital_loss
datos_adult <- datos_adult[,-c(8,9)]
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
dim(datos_adult)
```
Cuando hemos explorado los datos hemos podido observar lo siguiente: la sintaxis en el campo `income` es diferente al inicio y al final. Hay algunos datos que tienen un punto final. Vamos a depurar esa diferencia.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Quitamos el punto final de los valores
datos_adult$income <- gsub('<=50K.', '<=50K', datos_adult$income)
datos_adult$income <- gsub('>50K.', '>50K', datos_adult$income)
datos_adult$income <- as.factor(datos_adult$income)
```
```{r echo=TRUE, message=FALSE, warning=FALSE}
levels(datos_adult$income)
```
**Discretización de datos**

Cremamos una nueva variable `age_break` que almacena la edad discretizada por el métodos de partición en intervalos de la misma amplitud:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Discretizamos
datos_adult['age_break'] <- cut(datos_adult$age, breaks = c(-Inf,19,29,39,49,59,69,Inf), labels = c('<20','20-29','30-39','40-49','50-59','60-69','>70'))
```
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Vista del numero de registros en cada uno de los intervalos
summary(datos_adult$age_break)
```
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Vemos como se agrupan los datos.
plot(datos_adult$age_break,xlab='Intervalos de edad', ylab='N° Registros', col='blue')
```


En el gráfico se observa que el grupo de edad más representado es el que va desde los 30 hasta los 39 años.

De forma análoga dividimos el atributo `hours_per_week` en intervalos:
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Discretizamos
datos_adult['hours_break'] <- cut(datos_adult$hours_per_week, breaks = c(-Inf,19,39,44,49,59,Inf), labels = c('<20','20-39','40-44','45-49','50-59','>60'))
```
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Vista del numero de registros en cada uno de los intervalos
plot(datos_adult$hours_break, xlab='Horas trabajadas a la semana', ylab='N° Registros', col=1:6)
```


La cantidad de horas a la semana que más gente trabaja es de 40 a 44 horas con mucha diferencia sobre los demás intervalos.

**Transformación de los datos**

Vemos los nombres de los países existentes en la tabla de datos:

```{r echo=TRUE, message=FALSE, warning=FALSE}
levels(datos_adult$native_country)
```
Ahora vamos a unirlos por regiones en una nueva variable `country_region` con vistas al posterior análisis. La separación será asia, europa, eeuu y america (el resto de paises que no pertenece a eeuu).

```{r echo=TRUE, message=FALSE, warning=FALSE}
# creamos los nuevos valores que recogeran los nombres de paises por region
america <- c('Columbia', 'Cuba', 'Ecuador', 'Guatemala', 'Jamaica', 'Nicaragua', 
                     'Puerto-Rico', 'Dominican-Republic', 'El-Salvador', 
                     'Haiti', 'Honduras', 'Mexico', 'Peru', 'Trinadad&Tobago')
asia <- c('Cambodia', 'China', 'Hong', 'India', 'Iran', 'Laos', 'Thailand',
               'Japan', 'Taiwan', 'Vietnam')
europa <- c('England', 'Germany', 'Holand-Netherlands', 'Hungary', 'Ireland', 
                 'France', 'Greece', 'Italy', 'Poland', 'Portugal', 'Scotland', 'Yugoslavia')
eeuu <- c('Outlying-US(Guam-USVI-etc)', 'United-States')
# creamos la variable country_region y le damos los valores
country_region = ifelse(datos_adult$native_country %in% america, 'America',
                ifelse(datos_adult$native_country %in% asia, 'Asia',
                ifelse(datos_adult$native_country %in% europa, 'Europa', 'EEUU')))
datos_adult <- mutate(datos_adult,country_region)
# la pasamos a factor
datos_adult$country_region <- as.factor(datos_adult$country_region)
```
```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(datos_adult$country_region)
```

**Análisis visual del juego de datos**

Gráficos de barras de variables categóricas

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Para el atributo workclass
ggplot(datos_adult, aes(x=workclass)) + ggtitle("Situación Laboral") + xlab("Tipo de trabajo") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..))) + ylab("Porcentaje") + coord_flip() + 
  scale_x_discrete(limits = rev(levels(datos_adult$workclass)))
# Para el atributo education
ggplot(datos_adult, aes(x=education)) + ggtitle("Educación") + xlab("Educacion") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..))) + ylab("Porcentaje") + coord_flip() +
  scale_x_discrete(limits = rev(levels(datos_adult$education)))
# Para el atributo occupation
ggplot(datos_adult, aes(x=occupation)) + ggtitle("Ocupación") + xlab("Ocupacion") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..))) + ylab("Porcentaje") + coord_flip() +
  scale_x_discrete(limits = rev(levels(datos_adult$occupation)))
# Para el atributo marital_status
ggplot(datos_adult, aes(x=marital_status)) + ggtitle("Estado civil") + xlab("Estado civil") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..))) + ylab("Porcentaje") + coord_flip() +
  scale_x_discrete(limits = rev(levels(datos_adult$marital_status)))
# Para el atributo country_region
ggplot(datos_adult, aes(x=country_region)) + ggtitle("Regiones") + xlab("Regiones") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..))) + ylab("Porcentaje") + coord_flip() + 
  scale_x_discrete(limits = rev(levels(datos_adult$country_region))) 
```


Gráficos circulares de variables categóricas

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Para el atributo race
ggplot(datos_adult, aes(x=factor(1), fill=datos_adult$race)) + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 1) + coord_polar(theta="y") + 
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), legend.title=element_blank()) + 
  xlab("") + ylab("") + ggtitle("Raza")
# Para el atributo sex
ggplot(datos_adult, aes(x=factor(1), fill=datos_adult$sex)) + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 1) + coord_polar(theta="y") + 
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), legend.title=element_blank()) + 
  xlab("") + ylab("") + ggtitle("Sexo") 
```


Ahora que ya hemos revisado algunas de las variables y tenemos una idea de la distribución de los datos, vamos a analizar la relación del nivel de ingresos `income` con el resto de parámetros:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Primero revisamos la distribucion de la variable income sola
ggplot(datos_adult, aes(x=datos_adult$income, fill=datos_adult$income)) + 
  geom_bar(aes(y=100*(..count..)/sum(..count..))) +
  labs(x = "Ingresos",y = "Porcentaje", fill = "Income") + ggtitle("Nivel de ingresos") +
  geom_text(aes(label = scales::percent((..count..)/sum(..count..)),
                      y = (..count..)/sum(..count..) ), stat = "count", vjust=-5, size = 3) 
```


El gráfico anterior nos muestra el porcentaje de personas que ganan menos de 50 mil al año (75%) y más de 50 mil (25%).

Veamos ahora qué ocurre si diferenciamos por sexos:

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(datos_adult, aes(x=datos_adult$income, fill=datos_adult$income)) + 
  geom_bar(aes(y=100*(..count..)/sum(..count..))) +
  labs(x = "Ingresos",y = "Porcentaje", fill = "Income") + 
  ggtitle("Nivel de ingresos por sexo") +
  geom_text(aes(label = scales::percent((..count..)/sum(..count..)), y = (..count..)/sum(..count..) ),   stat = "count", vjust=-5, size = 3) + facet_grid(~datos_adult$sex)
```

En este gráfico podemos ver el porcentaje de mujeres que ganan más de 50 mil al año (3.7%) frente a las que ganan menos de 50 mil (28.8%) y en hombres ocurre que un 21.1% gana más de 50 mil y un 46.4% menos.

Nivel de ingresos vs Nivel de educación:

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(datos_adult, aes(x=datos_adult$education, fill=datos_adult$income)) + 
  geom_bar(aes(y=100*(..count..)/sum(..count..))) +
  labs(x = "Educacion",y = "Porcentaje", fill = "Income") + 
  ggtitle("Nivel de ingresos vs Nivel de educación") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```


Nivel de ingresos vs Ocupación:

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(datos_adult, aes(x=datos_adult$occupation, fill=datos_adult$income)) + 
  geom_bar(aes(y=100*(..count..)/sum(..count..))) +
  labs(x = "Ocupación",y = "Porcentaje", fill = "Income") + 
  ggtitle("Nivel de ingresos vs Ocupación") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Nivel de ingresos vs Región:

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(datos_adult, aes(x=datos_adult$country_region, fill=datos_adult$income)) + 
  geom_bar(aes(y=100*(..count..)/sum(..count..))) +
  labs(x = "Región",y = "Porcentaje", fill = "Income") + 
  ggtitle("Nivel de ingresos vs Región") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Nivel de ingresos vs Rango de Edad:

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(datos_adult, aes(x=datos_adult$age_break, fill=datos_adult$income)) + 
  geom_bar(aes(y=100*(..count..)/sum(..count..))) +
  labs(x = "Rango de edad",y = "Porcentaje", fill = "Income") + 
  ggtitle("Nivel de ingresos vs Edad") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

En el gráfico superior entendemos que en el rango de edad de 40-49 es donde más personas ganan más de 50 mil. Vemamos estas dos variables más a fondo en otro gráfico:

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(datos_adult, aes(x = datos_adult$age, fill = datos_adult$income)) + 
  geom_density(alpha = 0.3) + 
  scale_x_continuous(breaks = seq(0, 95, 5)) + 
  labs(y='', x = 'Edad', fill= 'Income')
```

Efectivamente, aqui observamos que donde más personas ganan mas de 50 mil es alrededor de los 45 años y donde más personas ganan menos de 50 mil es cerca de lso 24 años.

Horas trabajadas a la semana según Ingresos:

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(datos_adult, aes(x=datos_adult$hours_break, fill=datos_adult$hours_break)) + 
  geom_bar(aes(y=100*(..count..)/sum(..count..))) +
  labs(x = "Horas trabajadas",y = "Porcentaje", fill = "Horas por semana") + 
  ggtitle("Horas trabajadas a la semana según Ingresos") +
  geom_text(aes(label = scales::percent((..count..)/sum(..count..)), y = (..count..)/sum(..count..) ),   stat = "count", size = 2.5) + facet_grid(~datos_adult$income)
```

***
## Conclusiones
***
* El dataset Adult original contiene 48842 registros y 15 variables de tipo entero y factor (cadenas de caracteres) de las cuales se hace un resumen detallado en el estudio.
*	Durante el desarrollo de la PEC se ha manipulado el dataset original para reducir sus variables, crear nuevos indicadores, eliminar registros sin datos, crear nuevos atributos de los ya existentes, clasificar y discretizar datos con el objetivo de prepara el dataset para un posterior análisis.
*	El análisis se ha ejecutado sobre 45222 registros del dataset.
*	El alcance del análisis puede ser infinito y se pueden innumerables relaciones pero para el cumplimineto de esta PEC, el estudio se ha centrado en ver gráficamente la distribución de las variables categóricas y resolver la relación del nivel de ingresos de los individuos con respecto al sexo, edad, nivel de educación, ocupación, región y horas trabajadas para poder enumerar las siguientes conclusiones:
    + El rango de edad más representado es el de 30 a 39 años seguido del de 20 a 29 años. 
    + El intervalo de horas a la semana trabajadas más frecuente es el de 40 a 44 horas.
    + Más del 70% de los censados trabaja en el ámibito Privado.
    + En cuanto a la educación lo mayoria son High School Graduate y en cuanto al estado civil lo más        común es casado seguido por nunca casado.
    + Más del 80% de los censados son originarios de EEUU de raza blanca.
    + Un 68% de los censados son hombres y un 32% mujeres.
    + El porcentaje de personas que ganan menos de 50 mil al año es 75%  y el porcentaje que gana más        de 50 mil es 25%.
    + El porcentaje de mujeres que ganan más de 50 mil al año es 3.7% frente a las que ganan menos de        50 mil que es 28.8%. En los hombres ocurre que un 21.1% gana más de 50 mil al año y un 46.4% gana       menos de 50 mil.
    + Considerando la eduacación, los graduados "Bachelors" son los que tienen el porcentaje más alto        de individuos ganado más de 50 mil al año.
    + En cuanto a la ocupación son los que ocupan puestos ejecutivos o de mangement los que tienen más       personas ganando mas de 50 mil seguidos de cerca por especialistas de su profesión.
    + El rango de edad entre 40 y 49 años es donde más personas ganan más de 50 mil.
    + Donde más personas ganan mas de 50 mil es alrededor de los 45 años y donde más personas ganan          menos de 50 mil es cerca de los 24 años.
    + Respecto a las horas semanales trabajadas, en ambos casos (ganar mas de 50 mil o menos), lo que        predomina es trabajar un rango de 40 a 44 horas.
  

***
## Referencias Bibliográficas 
***

**Sangüesa i Solé, R**. *El proceso de descubrimiento de conocimiento a partir de datos*. PID_00165727. UOC

**Sangüesa i Solé, R**. *Preparación de datos*. PID_00165728. UOC

**Caihuelas Quiles, R. Casas Roma, J. Gironés Roig, J. Minguillón Alfonso, J**.(2017). *Minería de datos: Modelos y Algoritmos*. Editorial UOC

**Gil Bellosta, Carlos J.**.(2018). *R para profesionales de los datos*. 

**RStudio IDE CHEAT SHEET**. Disponible en: http://rstudio.com

**Base R CHEAT SHEET**. Disponible en: http://rstudio.com

**R Markdown CHEAT SHEET**. Disponible en: http://rmarkdown.rstudio.com

**R Markdown Reference Guide**. Disponible en: http://rmarkdown.rstudio.com

**Duran Albareda , X**. *Manipulación de datos con la librería dplyr*. Laboratorio Minería de Datos. UOC

**Duran Albareda , X**. *Limpieza del conjunto de datos con R *. Laboratorio Minería de Datos. UOC

**Duran Albareda , X**. *Estadística descriptiva del conjunto de datos *. Laboratorio Minería de Datos. UOC

*UCI Machine Learning Repository: Adult Data Set*. Disponible en: https://archive.ics.uci.edu/ml/datasets/adult.

**Taralova, V**.*Census Data Project*. Disponible en: http://rstudio-pubs-static.s3.amazonaws.com/265200_a8d21a65d3d34b979c5aafb0de10c221.html.

**Zhu, H**.*Predicting Earning Potential using the Adult Dataset*. Disponible en: https://rstudio-pubs-static.s3.amazonaws.com/235617_51e06fa6c43b47d1b6daca2523b2f9e4.html.


***
# Rúbrica
***
Pregunta Concepto Peso en la nota final

1ª	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1ª	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

1b	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1b	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

1c	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1c	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

2 Se carga la base de datos, se visualiza su estructura y se explican los hechos básicos. 5%

2 Se estudia si existen atributos vacíos, y si es el caso, se adoptan medidas para tratar estos atributos. 2.5%

2 Se transforma algún atributo para adaptarlo en un estudio posterior. 2.5%

2 Se realiza alguna discretitzación de algún atributo. 2.5%

2 Se crea un indicador nuevo a partido otros atributos 2.5%

2 Se analizan los datos de forma visual y se extraen conclusiones tangibles. Hay que elaborar un discurso coherente y con conclusiones claras. 35%

2 Se trata en profundidad algún otro aspecto respecto a los datos presentado en el módulo 2 15%

2 Se ha buscado información adicional, se ha incluido en el documento de respuesta y las fuentes se han citado correctamente 5%